{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:50.609428Z","iopub.status.busy":"2024-07-23T09:09:50.608872Z","iopub.status.idle":"2024-07-23T09:09:52.265672Z","shell.execute_reply":"2024-07-23T09:09:52.264359Z","shell.execute_reply.started":"2024-07-23T09:09:50.609392Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-23T09:09:52.268723Z","iopub.status.busy":"2024-07-23T09:09:52.268107Z","iopub.status.idle":"2024-07-23T09:09:52.390838Z","shell.execute_reply":"2024-07-23T09:09:52.389665Z","shell.execute_reply.started":"2024-07-23T09:09:52.268684Z"},"trusted":true},"outputs":[],"source":["content = pd.read_csv('c:/Users/nathb/Downloads/Accenture/Content.csv')\n","Reactions = pd.read_csv('c:/Users/nathb/Downloads/Accenture/Reactions.csv')\n","Reactiontypes = pd.read_csv('c:/Users/nathb/Downloads/Accenture/ReactionTypes.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Cleaning and Polishing Content DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.392696Z","iopub.status.busy":"2024-07-23T09:09:52.392357Z","iopub.status.idle":"2024-07-23T09:09:52.420484Z","shell.execute_reply":"2024-07-23T09:09:52.419247Z","shell.execute_reply.started":"2024-07-23T09:09:52.392667Z"},"trusted":true},"outputs":[],"source":["content.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.422327Z","iopub.status.busy":"2024-07-23T09:09:52.421920Z","iopub.status.idle":"2024-07-23T09:09:52.430209Z","shell.execute_reply":"2024-07-23T09:09:52.429148Z","shell.execute_reply.started":"2024-07-23T09:09:52.422288Z"},"trusted":true},"outputs":[],"source":["content.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Shape, Null_values and Duplicates \n","\n","Null/ NaN:\n","In pandas, the isnull().sum() combination of methods is used to count the number of missing (null or NaN) values in each column of a DataFrame. It's a convenient way to quickly assess the amount of missing data in your dataset.\n","\n","isnull(): This method is used to create a Boolean mask that identifies missing values in a DataFrame. It returns a DataFrame of the same shape as the original, where each element is True if the corresponding element in the original DataFrame is missing (NaN), and False otherwise.\n","\n","sum(): After applying isnull(), you can use the sum() method on the resulting Boolean DataFrame. This method sums the True values (which represent missing values) along each column, effectively counting the number of missing values in each column.\n","\n","Datatypes: \n","The dtypes attribute in pandas is used to determine the data type of each column in a DataFrame. It provides information about the data type of the values stored in each column, which is important for understanding and working with your data, especially during the Exploratory Data Analysis (EDA) phase.\n","\n","Duplicates:\n","\n","The .duplicated().sum() combination of methods in pandas is used to count the number of duplicate rows in a DataFrame. It allows you to identify and quantify duplicate rows based on the values in all columns or a specific subset of columns.\n","\n","Here's how it works:\n","\n",".duplicated(): This method returns a Boolean Series that indicates whether each row is a duplicate of a previous row. It marks duplicate rows as True and non-duplicate rows as False.\n","\n",".sum(): After applying .duplicated(), you can use the .sum() method on the resulting Boolean Series to count the number of True values, which correspond to duplicate rows.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.433502Z","iopub.status.busy":"2024-07-23T09:09:52.433109Z","iopub.status.idle":"2024-07-23T09:09:52.457248Z","shell.execute_reply":"2024-07-23T09:09:52.456158Z","shell.execute_reply.started":"2024-07-23T09:09:52.433470Z"},"trusted":true},"outputs":[],"source":["#reviewing the shape, nulls and duplicates for conent df\n","\n","print (content.isnull().sum())\n","print(content.dtypes)\n","print(content.duplicated().sum())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.459134Z","iopub.status.busy":"2024-07-23T09:09:52.458790Z","iopub.status.idle":"2024-07-23T09:09:52.468773Z","shell.execute_reply":"2024-07-23T09:09:52.467612Z","shell.execute_reply.started":"2024-07-23T09:09:52.459106Z"},"trusted":true},"outputs":[],"source":["content = content.drop(columns=['Unnamed: 0','URL'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.470870Z","iopub.status.busy":"2024-07-23T09:09:52.470533Z","iopub.status.idle":"2024-07-23T09:09:52.486175Z","shell.execute_reply":"2024-07-23T09:09:52.484689Z","shell.execute_reply.started":"2024-07-23T09:09:52.470835Z"},"trusted":true},"outputs":[],"source":["content.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.488500Z","iopub.status.busy":"2024-07-23T09:09:52.488070Z","iopub.status.idle":"2024-07-23T09:09:52.496589Z","shell.execute_reply":"2024-07-23T09:09:52.495438Z","shell.execute_reply.started":"2024-07-23T09:09:52.488460Z"},"trusted":true},"outputs":[],"source":["content = content.rename(columns={'Type':'Content Type'})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.498657Z","iopub.status.busy":"2024-07-23T09:09:52.498165Z","iopub.status.idle":"2024-07-23T09:09:52.513012Z","shell.execute_reply":"2024-07-23T09:09:52.511718Z","shell.execute_reply.started":"2024-07-23T09:09:52.498600Z"},"trusted":true},"outputs":[],"source":["content['Category'] = content['Category'].str.replace('\"','').str.capitalize()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.515229Z","iopub.status.busy":"2024-07-23T09:09:52.514860Z","iopub.status.idle":"2024-07-23T09:09:52.532676Z","shell.execute_reply":"2024-07-23T09:09:52.531262Z","shell.execute_reply.started":"2024-07-23T09:09:52.515196Z"},"trusted":true},"outputs":[],"source":["content.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["# Cleaning and Polishing Reactions Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.537085Z","iopub.status.busy":"2024-07-23T09:09:52.536697Z","iopub.status.idle":"2024-07-23T09:09:52.556080Z","shell.execute_reply":"2024-07-23T09:09:52.554929Z","shell.execute_reply.started":"2024-07-23T09:09:52.537052Z"},"trusted":true},"outputs":[],"source":["Reactions.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.558414Z","iopub.status.busy":"2024-07-23T09:09:52.557867Z","iopub.status.idle":"2024-07-23T09:09:52.588112Z","shell.execute_reply":"2024-07-23T09:09:52.586864Z","shell.execute_reply.started":"2024-07-23T09:09:52.558373Z"},"trusted":true},"outputs":[],"source":["print(Reactions.isnull().sum())\n","print(Reactions.dtypes)\n","print(Reactions.duplicated().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.589956Z","iopub.status.busy":"2024-07-23T09:09:52.589550Z","iopub.status.idle":"2024-07-23T09:09:52.599133Z","shell.execute_reply":"2024-07-23T09:09:52.597734Z","shell.execute_reply.started":"2024-07-23T09:09:52.589926Z"},"trusted":true},"outputs":[],"source":["#Remove unwanted columns\n","Reactions = Reactions.drop(columns=['Unnamed: 0', 'User ID'])\n","\n","#Rename columns for clarity\n","Reactions =  Reactions.rename(columns={'Type' : 'Reaction Type'})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.605900Z","iopub.status.busy":"2024-07-23T09:09:52.605515Z","iopub.status.idle":"2024-07-23T09:09:52.618355Z","shell.execute_reply":"2024-07-23T09:09:52.616879Z","shell.execute_reply.started":"2024-07-23T09:09:52.605867Z"},"trusted":true},"outputs":[],"source":["Reactions.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["# Dropping Null Values\n","Since there are null values in Reactions dataframe, we need to drop NaN values. For that we need to remove rows with missing values.\n","*dropna()*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.620623Z","iopub.status.busy":"2024-07-23T09:09:52.620236Z","iopub.status.idle":"2024-07-23T09:09:52.641730Z","shell.execute_reply":"2024-07-23T09:09:52.640489Z","shell.execute_reply.started":"2024-07-23T09:09:52.620575Z"},"trusted":true},"outputs":[],"source":["Reactions.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.644325Z","iopub.status.busy":"2024-07-23T09:09:52.643912Z","iopub.status.idle":"2024-07-23T09:09:52.653389Z","shell.execute_reply":"2024-07-23T09:09:52.652110Z","shell.execute_reply.started":"2024-07-23T09:09:52.644288Z"},"trusted":true},"outputs":[],"source":["print(Reactions)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.655310Z","iopub.status.busy":"2024-07-23T09:09:52.654912Z","iopub.status.idle":"2024-07-23T09:09:52.677296Z","shell.execute_reply":"2024-07-23T09:09:52.675909Z","shell.execute_reply.started":"2024-07-23T09:09:52.655280Z"},"trusted":true},"outputs":[],"source":["Reactions=Reactions.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.679354Z","iopub.status.busy":"2024-07-23T09:09:52.678918Z","iopub.status.idle":"2024-07-23T09:09:52.692855Z","shell.execute_reply":"2024-07-23T09:09:52.691624Z","shell.execute_reply.started":"2024-07-23T09:09:52.679321Z"},"trusted":true},"outputs":[],"source":["Reactions.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Cleaning and Polishing ReactionTypes Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.695117Z","iopub.status.busy":"2024-07-23T09:09:52.694203Z","iopub.status.idle":"2024-07-23T09:09:52.708522Z","shell.execute_reply":"2024-07-23T09:09:52.707243Z","shell.execute_reply.started":"2024-07-23T09:09:52.695078Z"},"trusted":true},"outputs":[],"source":["Reactiontypes.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.710700Z","iopub.status.busy":"2024-07-23T09:09:52.710365Z","iopub.status.idle":"2024-07-23T09:09:52.721247Z","shell.execute_reply":"2024-07-23T09:09:52.719892Z","shell.execute_reply.started":"2024-07-23T09:09:52.710665Z"},"trusted":true},"outputs":[],"source":["print(Reactiontypes.shape)\n","print(Reactiontypes.isnull().sum())\n","print(Reactiontypes.dtypes)\n","print(Reactiontypes.duplicated().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.723188Z","iopub.status.busy":"2024-07-23T09:09:52.722409Z","iopub.status.idle":"2024-07-23T09:09:52.736546Z","shell.execute_reply":"2024-07-23T09:09:52.735251Z","shell.execute_reply.started":"2024-07-23T09:09:52.723153Z"},"trusted":true},"outputs":[],"source":["#Removing the unwanted columns\n","Reactiontypes = Reactiontypes.drop(columns=['Unnamed: 0'])\n","\n","#renaming column names for claryfication\n","Reactiontypes = Reactiontypes.rename(columns={'Type': 'Reaction Type'})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.738648Z","iopub.status.busy":"2024-07-23T09:09:52.738150Z","iopub.status.idle":"2024-07-23T09:09:52.754212Z","shell.execute_reply":"2024-07-23T09:09:52.752811Z","shell.execute_reply.started":"2024-07-23T09:09:52.738557Z"},"trusted":true},"outputs":[],"source":["Reactiontypes.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Merging the three dataframes into one\n","In the code you provided, on is a parameter used in the pd.merge() function to specify the column or columns on which you want to merge two DataFrames.\n","\n","Here's what it signifies:\n","\n","on: This parameter specifies the column(s) that serve as the key or common identifier for merging the two DataFrames. When you set on to a column name or a list of column names, the merge function uses those columns as the matching criteria to align rows between the two DataFrames. In other words, it's the column that both DataFrames share and use to combine data.\n","\n","For example: one_df= pd.concat('content','Reactions', on='Content_ID')\n","\n","You are merging two DataFrames, Reactions_df and Content_df, based on the column named 'Content ID'. This means that rows with the same 'Content ID' values in both DataFrames will be combined into a single row in the Content_merged DataFrame. The 'Content ID' column is acting as the key or identifier for this merge operation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.756172Z","iopub.status.busy":"2024-07-23T09:09:52.755713Z","iopub.status.idle":"2024-07-23T09:09:52.793603Z","shell.execute_reply":"2024-07-23T09:09:52.792472Z","shell.execute_reply.started":"2024-07-23T09:09:52.756132Z"},"trusted":true},"outputs":[],"source":["one_df= pd.merge(content, Reactions, on='Content ID')\n","Merged_df= pd.merge(one_df, Reactiontypes, on='Reaction Type')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.795408Z","iopub.status.busy":"2024-07-23T09:09:52.795081Z","iopub.status.idle":"2024-07-23T09:09:52.809806Z","shell.execute_reply":"2024-07-23T09:09:52.808394Z","shell.execute_reply.started":"2024-07-23T09:09:52.795380Z"},"trusted":true},"outputs":[],"source":["Merged_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Now making a new dataframe to store the top categoreis with scores"]},{"cell_type":"markdown","metadata":{},"source":["The code you provided is performing a grouping and aggregation operation using the groupby() method in pandas. Let's break down the code step by step:\n","\n","category_score = Merged_df.groupby('Category')['Score'].sum()\n","Merged_df: This is assumed to be a DataFrame containing your data.\n","\n",".groupby('Category'): This part of the code groups the rows in the DataFrame Merged_df based on the values in the 'Category' column. In simple terms, it's creating groups where each group corresponds to a unique category in the 'Category' column.\n","\n","['Score']: After grouping by 'Category', this part specifies that you want to work with the 'Score' column for the aggregation. In other words, you are interested in summing the 'Score' values within each category group.\n","\n",".sum(): Finally, you are applying the sum() function to each group of 'Score' values within each category. This will calculate the sum of scores for each category.\n","\n","The result, category_score, is a pandas Series or DataFrame (depending on the structure of your original data) that shows the total sum of scores for each unique category in the 'Category' column of your original data. Each category is used as an index, and the corresponding value represents the sum of scores for that category."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.811847Z","iopub.status.busy":"2024-07-23T09:09:52.811444Z","iopub.status.idle":"2024-07-23T09:09:52.829041Z","shell.execute_reply":"2024-07-23T09:09:52.827555Z","shell.execute_reply.started":"2024-07-23T09:09:52.811792Z"},"trusted":true},"outputs":[],"source":["category_score = Merged_df.groupby('Category')['Score'].sum()\n","print(category_score)"]},{"cell_type":"markdown","metadata":{},"source":["**Sorting the top five scores in descending order**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.831020Z","iopub.status.busy":"2024-07-23T09:09:52.830605Z","iopub.status.idle":"2024-07-23T09:09:52.838795Z","shell.execute_reply":"2024-07-23T09:09:52.837461Z","shell.execute_reply.started":"2024-07-23T09:09:52.830985Z"},"trusted":true},"outputs":[],"source":["top_categories = category_score.sort_values(ascending=False)[:5]\n","print(top_categories)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.840689Z","iopub.status.busy":"2024-07-23T09:09:52.840363Z","iopub.status.idle":"2024-07-23T09:09:52.851685Z","shell.execute_reply":"2024-07-23T09:09:52.850224Z","shell.execute_reply.started":"2024-07-23T09:09:52.840663Z"},"trusted":true},"outputs":[],"source":["Top_five = pd.DataFrame({'Category':top_categories.index, 'Score':top_categories.values})\n","print(Top_five)"]},{"cell_type":"markdown","metadata":{},"source":["# Converting the dataframes to xlsx files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install openpyxl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:09:52.854174Z","iopub.status.busy":"2024-07-23T09:09:52.853147Z","iopub.status.idle":"2024-07-23T09:10:00.164572Z","shell.execute_reply":"2024-07-23T09:10:00.163359Z","shell.execute_reply.started":"2024-07-23T09:09:52.854100Z"},"trusted":true},"outputs":[],"source":["with pd.ExcelWriter('data_final.xlsx') as writer:\n","    Merged_df.to_excel(writer, sheet_name='Merged Datasets')\n","    Top_five.to_excel(writer, sheet_name='Top five Categories')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.166618Z","iopub.status.busy":"2024-07-23T09:10:00.166096Z","iopub.status.idle":"2024-07-23T09:10:00.302254Z","shell.execute_reply":"2024-07-23T09:10:00.300919Z","shell.execute_reply.started":"2024-07-23T09:10:00.166585Z"},"trusted":true},"outputs":[],"source":["# Specify the file path where you want to save the CSV file\n","file_path = 'c:/Users/nathb/Downloads/Accenture/Merged_df.csv'\n","\n","# Use the to_csv() method to save the DataFrame as a CSV file\n","Merged_df.to_csv(file_path, index=False)  # Set index=False to exclude the index column\n","\n","print(f\"DataFrame has been saved as '{file_path}'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.304475Z","iopub.status.busy":"2024-07-23T09:10:00.303891Z","iopub.status.idle":"2024-07-23T09:10:00.312811Z","shell.execute_reply":"2024-07-23T09:10:00.311633Z","shell.execute_reply.started":"2024-07-23T09:10:00.304435Z"},"trusted":true},"outputs":[],"source":["# Specify the file path where you want to save the CSV file\n","file_path = 'Top_five.csv'\n","\n","# Use the to_csv() method to save the DataFrame as a CSV file\n","Top_five.to_csv(file_path, index=False)  # Set index=False to exclude the index column\n","\n","print(f\"DataFrame has been saved as '{file_path}'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.314838Z","iopub.status.busy":"2024-07-23T09:10:00.314465Z","iopub.status.idle":"2024-07-23T09:10:00.334524Z","shell.execute_reply":"2024-07-23T09:10:00.333128Z","shell.execute_reply.started":"2024-07-23T09:10:00.314792Z"},"trusted":true},"outputs":[],"source":["Merged_df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.336341Z","iopub.status.busy":"2024-07-23T09:10:00.335989Z","iopub.status.idle":"2024-07-23T09:10:00.348760Z","shell.execute_reply":"2024-07-23T09:10:00.347510Z","shell.execute_reply.started":"2024-07-23T09:10:00.336311Z"},"trusted":true},"outputs":[],"source":["Merged_df= Merged_df.drop(columns=['User ID'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.350601Z","iopub.status.busy":"2024-07-23T09:10:00.350279Z","iopub.status.idle":"2024-07-23T09:10:00.371129Z","shell.execute_reply":"2024-07-23T09:10:00.369986Z","shell.execute_reply.started":"2024-07-23T09:10:00.350575Z"},"trusted":true},"outputs":[],"source":["Merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.372733Z","iopub.status.busy":"2024-07-23T09:10:00.372422Z","iopub.status.idle":"2024-07-23T09:10:00.392922Z","shell.execute_reply":"2024-07-23T09:10:00.391701Z","shell.execute_reply.started":"2024-07-23T09:10:00.372708Z"},"trusted":true},"outputs":[],"source":["Merged_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.394889Z","iopub.status.busy":"2024-07-23T09:10:00.394482Z","iopub.status.idle":"2024-07-23T09:10:00.421650Z","shell.execute_reply":"2024-07-23T09:10:00.420525Z","shell.execute_reply.started":"2024-07-23T09:10:00.394841Z"},"trusted":true},"outputs":[],"source":["Merged_df.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.423342Z","iopub.status.busy":"2024-07-23T09:10:00.422979Z","iopub.status.idle":"2024-07-23T09:10:00.430024Z","shell.execute_reply":"2024-07-23T09:10:00.429033Z","shell.execute_reply.started":"2024-07-23T09:10:00.423312Z"},"trusted":true},"outputs":[],"source":["Merged_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.431734Z","iopub.status.busy":"2024-07-23T09:10:00.431409Z","iopub.status.idle":"2024-07-23T09:10:00.463030Z","shell.execute_reply":"2024-07-23T09:10:00.461798Z","shell.execute_reply.started":"2024-07-23T09:10:00.431707Z"},"trusted":true},"outputs":[],"source":["Merged_df.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:00.465336Z","iopub.status.busy":"2024-07-23T09:10:00.464970Z","iopub.status.idle":"2024-07-23T09:10:06.962973Z","shell.execute_reply":"2024-07-23T09:10:06.961649Z","shell.execute_reply.started":"2024-07-23T09:10:00.465304Z"},"trusted":true},"outputs":[],"source":["with pd.ExcelWriter('finaldataset.xlsx') as writer:\n","    Merged_df.to_excel(writer, sheet_name='Merged Datasets')\n","    Top_five.to_excel(writer, sheet_name='Top five Categories')"]},{"cell_type":"markdown","metadata":{},"source":["# Visualization and Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:06.964814Z","iopub.status.busy":"2024-07-23T09:10:06.964480Z","iopub.status.idle":"2024-07-23T09:10:07.364360Z","shell.execute_reply":"2024-07-23T09:10:07.363328Z","shell.execute_reply.started":"2024-07-23T09:10:06.964784Z"},"trusted":true},"outputs":[],"source":["sorted_categories = category_score.sort_values(ascending=False)\n","#colors = ['tomato', 'darkorange', 'gold', 'green', 'darkturquoise','mediumorchid']\n","fig, ax = plt.subplots(figsize=(15,6))\n","\n","ax.bar(sorted_categories.index, sorted_categories)\n","ax.set_title('Category Scores')\n","ax.set_xlabel('Categories')\n","ax.set_ylabel('Score')\n","plt.xticks(rotation=45)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Average Scores at different hours of the day. "]},{"cell_type":"markdown","metadata":{},"source":["# Line Chart with highlighed peak"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:07.366964Z","iopub.status.busy":"2024-07-23T09:10:07.366436Z","iopub.status.idle":"2024-07-23T09:10:07.401058Z","shell.execute_reply":"2024-07-23T09:10:07.399965Z","shell.execute_reply.started":"2024-07-23T09:10:07.366928Z"},"trusted":true},"outputs":[],"source":["# Convert the \"Datetime\" column to a datetime object\n","Merged_df['Datetime'] = pd.to_datetime(Merged_df['Datetime'], format='%Y-%m-%d %H:%M:%S')\n","\n","# average score per hour\n","hourly_scores = Merged_df.groupby(Merged_df['Datetime'].dt.hour)['Score'].mean()\n","\n","# Find peak hours\n","peak_hours = hourly_scores[hourly_scores > hourly_scores.mean()].index\n","\n","#average Scores\n","avg_score = hourly_scores.mean()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:07.409696Z","iopub.status.busy":"2024-07-23T09:10:07.409301Z","iopub.status.idle":"2024-07-23T09:10:07.416076Z","shell.execute_reply":"2024-07-23T09:10:07.414714Z","shell.execute_reply.started":"2024-07-23T09:10:07.409665Z"},"trusted":true},"outputs":[],"source":["print (peak_hours)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:07.417759Z","iopub.status.busy":"2024-07-23T09:10:07.417414Z","iopub.status.idle":"2024-07-23T09:10:07.433444Z","shell.execute_reply":"2024-07-23T09:10:07.432193Z","shell.execute_reply.started":"2024-07-23T09:10:07.417723Z"},"trusted":true},"outputs":[],"source":["top_peak_hours = hourly_scores.nlargest(3)\n","\n","# Print the top three peak engagement hours\n","print(\"Top Three Peak Engagement Hours:\")\n","for hour, score in top_peak_hours.items():\n","    print(f\"Hour: {hour}, Average Score: {score:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:52.043647Z","iopub.status.busy":"2024-07-23T09:10:52.042708Z","iopub.status.idle":"2024-07-23T09:10:52.063152Z","shell.execute_reply":"2024-07-23T09:10:52.061879Z","shell.execute_reply.started":"2024-07-23T09:10:52.043609Z"},"trusted":true},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","# Assuming you have already calculated 'hourly_scores', 'peak_hours', and 'avg_score' as before\n","\n","# Create a list of hour labels for the x-axis\n","hour_labels = [f\"{h}:00\" for h in range(24)]\n","\n","# Create a scatter trace for the peak hours\n","peak_trace = go.Scatter(\n","    x=peak_hours,\n","    y=[hourly_scores[hour] for hour in peak_hours],\n","    mode='markers',\n","    marker=dict(size=10, color='red'),\n","    text=[f\"Hour: {hour}<br>Average Score: {hourly_scores[hour]:.2f}\" for hour in peak_hours],\n","    name='Peak Hours'\n",")\n","\n","# Create a line trace for the average score\n","line_trace = go.Scatter(\n","    x=hourly_scores.index,\n","    y=hourly_scores,\n","    mode='lines',\n","    line=dict(color='blue'),\n","    name='Average Score'\n",")\n","\n","# Create a dashed line for the average score\n","avg_trace = go.Scatter(\n","    x=hourly_scores.index,\n","    y=[avg_score] * len(hourly_scores),\n","    mode='lines',\n","    line=dict(color='green', dash='dash'),\n","    name='Average Score (Mean)'\n",")\n","\n","# Create the layout for the plot\n","layout = go.Layout(\n","    title='Average Scores by Hour of Day',\n","    xaxis=dict(\n","        title='Hour of Day',\n","        tickvals=list(range(24)),\n","        ticktext=hour_labels,\n","        tickangle=45\n","    ),\n","    yaxis=dict(title='Average Score')\n",")\n","\n","# Create the figure and add traces\n","fig = go.Figure(data=[peak_trace, line_trace, avg_trace], layout=layout)\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Average Score per day of the week"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:56.869701Z","iopub.status.busy":"2024-07-23T09:10:56.869297Z","iopub.status.idle":"2024-07-23T09:10:56.895599Z","shell.execute_reply":"2024-07-23T09:10:56.894324Z","shell.execute_reply.started":"2024-07-23T09:10:56.869670Z"},"trusted":true},"outputs":[],"source":["#average scores per day of the week\n","daily_scores = Merged_df.groupby(Merged_df['Datetime'].dt.dayofweek)['Score'].mean()\n","\n","#peak days\n","peak_days= daily_scores[daily_scores>daily_scores.mean()].index\n","\n","#average Scores\n","avg_score = daily_scores.mean()\n","\n","#create a list for the day labels i.e. x-axis\n","\n","day_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n","\n","#create a scatter trace for peak days\n","\n","peak_trace = go.Scatter(\n","    x= peak_days,\n","    y= [daily_scores[day] for day in peak_days],\n","    mode='markers',\n","    marker=dict(size=10, color='red'),\n","    text= [f\"Day: {day}<br>Average Score : {daily_scores[day] : .2f}\" for day in peak_days], \n","    name= \"Peak Days\"\n",")\n","\n","#Create a line trace for the average scores\n","line_trace = go.Scatter(\n","    x= daily_scores.index,\n","    y= daily_scores,\n","    mode= 'lines',\n","    line= dict(color='blue'),\n","    name= 'Average Score'\n",")\n","\n","# Create a dashed line for the average score\n","avg_trace = go.Scatter(\n","    x=daily_scores.index,\n","    y=[avg_score] * len(hourly_scores),\n","    mode='lines',\n","    line=dict(color='green', dash='dash'),\n","    name='Average Score (Mean)'\n",")\n","\n","# Create the layout for the plot\n","layout = go.Layout(\n","    title='Average Scores by Day of the week',\n","    xaxis=dict(\n","        title='Day of the week',\n","        tickvals=list(range(7)),\n","        ticktext=day_labels,\n","        tickangle=45\n","    ),\n","    yaxis=dict(title='Average Score')\n",")\n","\n","# Create the figure and add traces\n","fig = go.Figure(data=[peak_trace, line_trace, avg_trace], layout=layout)\n","\n","# Show the plot\n","fig.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-07-23T09:11:00.561327Z","iopub.status.busy":"2024-07-23T09:11:00.560911Z","iopub.status.idle":"2024-07-23T09:11:00.567785Z","shell.execute_reply":"2024-07-23T09:11:00.566645Z","shell.execute_reply.started":"2024-07-23T09:11:00.561295Z"},"trusted":true},"outputs":[],"source":["# Find the top 3 peak days\n","top_peak_days = daily_scores.nlargest(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:01.818722Z","iopub.status.busy":"2024-07-23T09:11:01.818301Z","iopub.status.idle":"2024-07-23T09:11:01.826055Z","shell.execute_reply":"2024-07-23T09:11:01.824592Z","shell.execute_reply.started":"2024-07-23T09:11:01.818689Z"},"trusted":true},"outputs":[],"source":["print(\"Top Three Peak Engagement Days:\")\n","for day in top_peak_days.index:\n","    print(f\"Day: {day_labels[day]}, Average Score: {top_peak_days[day]:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Content Type Percentages using pie chart"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:03.740592Z","iopub.status.busy":"2024-07-23T09:11:03.740110Z","iopub.status.idle":"2024-07-23T09:11:03.804010Z","shell.execute_reply":"2024-07-23T09:11:03.802622Z","shell.execute_reply.started":"2024-07-23T09:11:03.740557Z"},"trusted":true},"outputs":[],"source":["import plotly.express as px\n","\n","#Count the number of content types\n","type_counts = Merged_df.groupby('Content Type').size()\n","\n","# Create an interactive pie chart using Plotly Express\n","fig = px.pie(\n","    names=type_counts.index, \n","    values=type_counts.values,\n","    title='Content Type Percentages', \n","    hole=0.6,\n","    labels={'names': 'Content Type'}\n",")\n","\n","# Customize the layout to adjust size (width and height)\n","fig.update_layout(\n","    showlegend=True,\n","    width=600,  # Adjust the width as needed\n","    height=400  # Adjust the height as needed\n",")\n","\n","# Customize textinfo using update_traces\n","fig.update_traces(textinfo='percent+label')\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.063125Z","iopub.status.busy":"2024-07-23T09:10:10.062375Z","iopub.status.idle":"2024-07-23T09:10:10.073724Z","shell.execute_reply":"2024-07-23T09:10:10.072171Z","shell.execute_reply.started":"2024-07-23T09:10:10.063083Z"},"trusted":true},"outputs":[],"source":["type_counts.sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Number of Content Items by Categories"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.076619Z","iopub.status.busy":"2024-07-23T09:10:10.076138Z","iopub.status.idle":"2024-07-23T09:10:10.097832Z","shell.execute_reply":"2024-07-23T09:10:10.096401Z","shell.execute_reply.started":"2024-07-23T09:10:10.076579Z"},"trusted":true},"outputs":[],"source":["categories = Merged_df['Category'].nunique()\n","categories"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.100047Z","iopub.status.busy":"2024-07-23T09:10:10.099629Z","iopub.status.idle":"2024-07-23T09:10:10.113321Z","shell.execute_reply":"2024-07-23T09:10:10.112052Z","shell.execute_reply.started":"2024-07-23T09:10:10.100002Z"},"trusted":true},"outputs":[],"source":["category_counts= Merged_df['Category'].value_counts()\n","category_counts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.114885Z","iopub.status.busy":"2024-07-23T09:10:10.114547Z","iopub.status.idle":"2024-07-23T09:10:10.209925Z","shell.execute_reply":"2024-07-23T09:10:10.208894Z","shell.execute_reply.started":"2024-07-23T09:10:10.114855Z"},"trusted":true},"outputs":[],"source":["# Create an interactive bar plot using Plotly Express\n","fig = px.bar(\n","    x=category_counts.index,  # Use the index as x-values (category names)\n","    y=category_counts.values,  # Use values as y-values (count values)\n","    title='Number of Content Items by Category',\n","    labels={'x': 'Category', 'y': 'Number of Content Items'},\n","    text=category_counts.values,  # Display count values on bars\n",")\n","\n","# Customize the layout (optional)\n","fig.update_layout(\n","    xaxis_title='Category',\n","    yaxis_title='Number of Content Items',\n","    xaxis=dict(tickangle=45),\n","    showlegend=False\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.211422Z","iopub.status.busy":"2024-07-23T09:10:10.211108Z","iopub.status.idle":"2024-07-23T09:10:10.220105Z","shell.execute_reply":"2024-07-23T09:10:10.219083Z","shell.execute_reply.started":"2024-07-23T09:10:10.211396Z"},"trusted":true},"outputs":[],"source":["Merged_df['Month'] = Merged_df['Datetime'].dt.month"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:12.545549Z","iopub.status.busy":"2024-07-23T09:11:12.544679Z","iopub.status.idle":"2024-07-23T09:11:12.552943Z","shell.execute_reply":"2024-07-23T09:11:12.551598Z","shell.execute_reply.started":"2024-07-23T09:11:12.545504Z"},"trusted":true},"outputs":[],"source":["import calendar\n","#month with the most posts\n","month_with_most_posts = Merged_df['Month'].value_counts().idxmax()\n","\n","#converting the output which will be an integer to the name of the month.\n","month_name = calendar.month_name[month_with_most_posts]\n","print(f\"The month with the most posts is: {month_name}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:14.527102Z","iopub.status.busy":"2024-07-23T09:11:14.526698Z","iopub.status.idle":"2024-07-23T09:11:14.553507Z","shell.execute_reply":"2024-07-23T09:11:14.552205Z","shell.execute_reply.started":"2024-07-23T09:11:14.527071Z"},"trusted":true},"outputs":[],"source":["monthly_posts = Merged_df.groupby('Month')['Content ID'].count()\n","\n","# Calculate the average posts per month\n","avg_posts = monthly_posts.mean()\n","\n","# Define month labels\n","month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n","\n","# Create a line chart using Plotly\n","fig = go.Figure()\n","\n","# Add a trace for the monthly posts\n","fig.add_trace(go.Scatter(\n","    x=monthly_posts.index,\n","    y=monthly_posts,\n","    mode='lines',\n","    line=dict(color='blue'),\n","    name='Monthly Posts'\n","))\n","\n","# Add a horizontal dashed line for the average posts\n","fig.add_shape(\n","    type='line',\n","    x0=monthly_posts.index[0],\n","    x1=monthly_posts.index[-1],\n","    y0=avg_posts,\n","    y1=avg_posts,\n","    line=dict(color='red', dash='dash'),\n","    name='Average Posts'\n",")\n","\n","# Find and highlight peak months\n","peak_months = monthly_posts[monthly_posts == monthly_posts.max()].index.tolist()\n","fig.add_trace(go.Scatter(\n","    x=peak_months,\n","    y=[monthly_posts[i] for i in peak_months],\n","    mode='markers',\n","    marker=dict(color='red', size=10),\n","    name='Peak Activity'\n","))\n","\n","# Customize the layout\n","fig.update_layout(\n","    xaxis=dict(\n","        title='Month',\n","        tickvals=list(range(1, 13)),\n","        ticktext=month_labels\n","    ),\n","    yaxis=dict(title='Count of Posts'),\n","    title='Average Scores per Month of the Year',\n","    showlegend=True\n","    \n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:20.099415Z","iopub.status.busy":"2024-07-23T09:11:20.098986Z","iopub.status.idle":"2024-07-23T09:11:20.107913Z","shell.execute_reply":"2024-07-23T09:11:20.106495Z","shell.execute_reply.started":"2024-07-23T09:11:20.099386Z"},"trusted":true},"outputs":[],"source":["top_peak_months = monthly_posts.nlargest(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:21.222886Z","iopub.status.busy":"2024-07-23T09:11:21.222468Z","iopub.status.idle":"2024-07-23T09:11:21.229659Z","shell.execute_reply":"2024-07-23T09:11:21.228258Z","shell.execute_reply.started":"2024-07-23T09:11:21.222856Z"},"trusted":true},"outputs":[],"source":["# Print the top 3 peak months\n","print(\"Top Three Peak Months:\")\n","for month in top_peak_months.index:\n","    print(f\"Month: {calendar.month_name[month]}, Total Posts: {top_peak_months[month]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.297783Z","iopub.status.busy":"2024-07-23T09:10:10.297376Z","iopub.status.idle":"2024-07-23T09:10:10.316845Z","shell.execute_reply":"2024-07-23T09:10:10.315690Z","shell.execute_reply.started":"2024-07-23T09:10:10.297745Z"},"trusted":true},"outputs":[],"source":["Merged_df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.318538Z","iopub.status.busy":"2024-07-23T09:10:10.318214Z","iopub.status.idle":"2024-07-23T09:10:10.342625Z","shell.execute_reply":"2024-07-23T09:10:10.341410Z","shell.execute_reply.started":"2024-07-23T09:10:10.318512Z"},"trusted":true},"outputs":[],"source":["# Extract the year from the 'Datetime' column\n","Merged_df['Year'] = Merged_df['Datetime'].dt.year\n","\n","# Now, you can count the number of contents uploaded in a specific year (e.g., 2023)\n","year_to_count = Merged_df['Year'[::]]  # Change this to the desired year\n","total_contents_in_year = len(Merged_df[Merged_df['Year'] == year_to_count])\n","\n","# Print the total number of contents uploaded in the specified year\n","print(f\"Total contents uploaded in {year_to_count}: {total_contents_in_year}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Insights :\n","1. In our dataset, which consists of content across 16 different categories, we've uncovered some significant insights.  Our content portfolio encompasses a wide array of content categories, each with its unique appeal and significance.\n","2. Among these categories, we observe a range of topics that resonate strongly with our audience. Notably, the top 5 content categories that have garnered the most attention and engagement are Animals, Science, Healthy Eating, Technology, and Food. These categories appear to resonate strongly with our audience and have generated substantial interest.\n","3. With a substantial count of 1897 content items, the Animals category stands at the forefront, showcasing its remarkable popularity and the strong affinity our audience holds for content related to the natural world and animal kingdom.\n","4. In our analysis, we've identified a diverse range of content types, including photos, videos, audios, and gifs. Among these, photos emerge as the dominant content type, comprising 26.8% of the total content volume. This is closely followed by videos at 25.4%, while audios and gifs contribute 23% and 24.7%, respectively. \n","5. In our analysis, May stands out as the month with the highest volume of posts making it a pivotal month in our data timeline.\n","6. Thursdays, Fridays, and Sundays emerge as the peak engagement days, offering prime opportunities for content impact.\n","7. Peak engagement hours at 15:00, 17:00, and 21:00 signify optimal windows for content delivery and interaction, strategically capitalizing on user enthusiasm throughout the day."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.344383Z","iopub.status.busy":"2024-07-23T09:10:10.344002Z","iopub.status.idle":"2024-07-23T09:10:10.400841Z","shell.execute_reply":"2024-07-23T09:10:10.399591Z","shell.execute_reply.started":"2024-07-23T09:10:10.344354Z"},"trusted":true},"outputs":[],"source":["import plotly.express as px\n","\n","# Sample data (replace with your actual data)\n","categories = ['Animals', 'Science', 'Healthy Eating', 'Technology', 'Food']\n","content_counts = [1897, 1796, 1717, 1698, 1699]\n","\n","# Create a DataFrame from the data\n","data = {'Category': categories, 'Content Count': content_counts}\n","df = pd.DataFrame(data)\n","\n","# Define a custom color palette\n","custom_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # You can specify your own colors here\n","\n","# Create an interactive pie chart with custom colors\n","fig = px.pie(df, names='Category', values='Content Count', title='Top 5 Content Categories', hole=0.6, color_discrete_sequence=custom_colors)\n","fig.update_traces(textinfo='percent+label')\n","\n","# Show the chart\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.402567Z","iopub.status.busy":"2024-07-23T09:10:10.402191Z","iopub.status.idle":"2024-07-23T09:10:10.421992Z","shell.execute_reply":"2024-07-23T09:10:10.420890Z","shell.execute_reply.started":"2024-07-23T09:10:10.402537Z"},"trusted":true},"outputs":[],"source":["Merged_df.head(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.423956Z","iopub.status.busy":"2024-07-23T09:10:10.423574Z","iopub.status.idle":"2024-07-23T09:10:10.433611Z","shell.execute_reply":"2024-07-23T09:10:10.432557Z","shell.execute_reply.started":"2024-07-23T09:10:10.423919Z"},"trusted":true},"outputs":[],"source":["print(Merged_df['Sentiment'].unique())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.435876Z","iopub.status.busy":"2024-07-23T09:10:10.434920Z","iopub.status.idle":"2024-07-23T09:10:10.444913Z","shell.execute_reply":"2024-07-23T09:10:10.443721Z","shell.execute_reply.started":"2024-07-23T09:10:10.435836Z"},"trusted":true},"outputs":[],"source":["sentiment_mapping = {'negative': -1, 'positive': 1, 'neutral': 0}\n","Merged_df['Sentiment'] = Merged_df['Sentiment'].map(sentiment_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:10:10.446740Z","iopub.status.busy":"2024-07-23T09:10:10.446327Z","iopub.status.idle":"2024-07-23T09:10:10.462337Z","shell.execute_reply":"2024-07-23T09:10:10.461245Z","shell.execute_reply.started":"2024-07-23T09:10:10.446696Z"},"trusted":true},"outputs":[],"source":["Merged_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-07-23T09:10:10.645620Z","iopub.status.idle":"2024-07-23T09:10:10.646014Z","shell.execute_reply":"2024-07-23T09:10:10.645850Z","shell.execute_reply.started":"2024-07-23T09:10:10.645832Z"},"trusted":true},"outputs":[],"source":["print(sentiment_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:33.194765Z","iopub.status.busy":"2024-07-23T09:11:33.193756Z","iopub.status.idle":"2024-07-23T09:11:33.290231Z","shell.execute_reply":"2024-07-23T09:11:33.289022Z","shell.execute_reply.started":"2024-07-23T09:11:33.194723Z"},"trusted":true},"outputs":[],"source":["# Group the data by 'Category' and 'Sentiment' and count occurrences\n","sentiment_counts = Merged_df.groupby(['Category', 'Sentiment']).size().reset_index(name='Count')\n","\n","# Create a custom color map for sentiment categories\n","color_map = {'positive': '#90EE90', 'negative': '#FF0000', 'neutral': '#ADD8E6'}\n","\n","# Create a stacked bar chart using Plotly Express\n","fig = px.bar(sentiment_counts, x='Category', y='Count', color='Sentiment',\n","             title='Sentiment Distribution by Content Category',\n","             color_discrete_map=color_map)\n","\n","# Customize the layout (optional)\n","fig.update_xaxes(title='Content Category')\n","fig.update_yaxes(title='Count')\n","fig.update_traces(marker_line_width=0, opacity=0.8)  # Customize appearance\n","\n","# Show the interactive plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:36.652233Z","iopub.status.busy":"2024-07-23T09:11:36.651701Z","iopub.status.idle":"2024-07-23T09:11:36.664789Z","shell.execute_reply":"2024-07-23T09:11:36.663488Z","shell.execute_reply.started":"2024-07-23T09:11:36.652188Z"},"trusted":true},"outputs":[],"source":["# Group the sentiment_counts DataFrame by 'Category' and calculate the total count\n","total_counts_per_category = sentiment_counts.groupby('Category')['Count'].sum().reset_index()\n","\n","# Print the total counts per category\n","print(total_counts_per_category)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:42.050661Z","iopub.status.busy":"2024-07-23T09:11:42.050252Z","iopub.status.idle":"2024-07-23T09:11:42.074318Z","shell.execute_reply":"2024-07-23T09:11:42.072941Z","shell.execute_reply.started":"2024-07-23T09:11:42.050628Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Filter the sentiment_counts DataFrame for positive sentiment\n","positive_sentiment_counts = sentiment_counts[sentiment_counts['Sentiment'] == 'positive']\n","positive_sentiment_counts = positive_sentiment_counts[['Category', 'Count']]\n","positive_sentiment_counts = positive_sentiment_counts.rename(columns={'Count': 'Positive Count'})\n","\n","# Filter the sentiment_counts DataFrame for neutral sentiment\n","neutral_sentiment_counts = sentiment_counts[sentiment_counts['Sentiment'] == 'neutral']\n","neutral_sentiment_counts = neutral_sentiment_counts[['Category', 'Count']]\n","neutral_sentiment_counts = neutral_sentiment_counts.rename(columns={'Count': 'Neutral Count'})\n","\n","# Filter the sentiment_counts DataFrame for negative sentiment\n","negative_sentiment_counts = sentiment_counts[sentiment_counts['Sentiment'] == 'negative']\n","negative_sentiment_counts = negative_sentiment_counts[['Category', 'Count']]\n","negative_sentiment_counts = negative_sentiment_counts.rename(columns={'Count': 'Negative Count'})\n","\n","# Merge the three DataFrames based on the 'Category' column\n","combined_sentiment_counts = pd.merge(positive_sentiment_counts, neutral_sentiment_counts, on='Category', how='outer')\n","combined_sentiment_counts = pd.merge(combined_sentiment_counts, negative_sentiment_counts, on='Category', how='outer')\n","\n","# Fill NaN values with 0\n","combined_sentiment_counts = combined_sentiment_counts.fillna(0)\n","\n","# Print the combined sentiment counts table\n","print(\"Combined Sentiment Counts:\")\n","print(combined_sentiment_counts)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:46.342731Z","iopub.status.busy":"2024-07-23T09:11:46.341746Z","iopub.status.idle":"2024-07-23T09:11:46.435076Z","shell.execute_reply":"2024-07-23T09:11:46.433681Z","shell.execute_reply.started":"2024-07-23T09:11:46.342679Z"},"trusted":true},"outputs":[],"source":["\n","# Group the data by 'Content Type' and 'Sentiment' and count occurrences\n","sentiment_counts = Merged_df.groupby(['Content Type', 'Sentiment']).size().reset_index(name='Count')\n","\n","# Create a custom color map for sentiment categories\n","color_map = {'positive': '#8BC34A', 'negative': '#FF5722', 'neutral': '#757575'}\n","\n","# Create a stacked bar chart using Plotly Express with custom colors\n","fig = px.bar(sentiment_counts, x='Content Type', y='Count', color='Sentiment',\n","             title='Sentiment Distribution by Content Type',\n","             color_discrete_map=color_map)  # Specify custom colors\n","\n","# Customize the layout (optional)\n","fig.update_xaxes(title='Content Type')\n","fig.update_yaxes(title='Count')\n","fig.update_traces(marker_line_width=0, opacity=0.8)  # Customize appearance\n","\n","# Show the interactive plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:55.644926Z","iopub.status.busy":"2024-07-23T09:11:55.644502Z","iopub.status.idle":"2024-07-23T09:11:55.655396Z","shell.execute_reply":"2024-07-23T09:11:55.653879Z","shell.execute_reply.started":"2024-07-23T09:11:55.644893Z"},"trusted":true},"outputs":[],"source":["# Group the data by 'Content Type' and sum the 'Count' column to get the total counts per Content Type\n","total_counts_per_content_type = sentiment_counts.groupby('Content Type')['Count'].sum().reset_index()\n","\n","# Print the total counts per Content Type\n","print(total_counts_per_content_type)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:11:58.930226Z","iopub.status.busy":"2024-07-23T09:11:58.929020Z","iopub.status.idle":"2024-07-23T09:11:58.942784Z","shell.execute_reply":"2024-07-23T09:11:58.941551Z","shell.execute_reply.started":"2024-07-23T09:11:58.930183Z"},"trusted":true},"outputs":[],"source":["# Pivot the 'sentiment_counts' DataFrame to have separate columns for positive, neutral, and negative sentiments\n","pivot_sentiments = sentiment_counts.pivot(index='Content Type', columns='Sentiment', values='Count').reset_index()\n","\n","# Rename the columns for clarity\n","pivot_sentiments.columns = ['Content Type', 'Negative', 'Neutral', 'Positive']\n","\n","# Print the pivot table\n","print(pivot_sentiments)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:12:00.851295Z","iopub.status.busy":"2024-07-23T09:12:00.850848Z","iopub.status.idle":"2024-07-23T09:12:01.284631Z","shell.execute_reply":"2024-07-23T09:12:01.283176Z","shell.execute_reply.started":"2024-07-23T09:12:00.851261Z"},"trusted":true},"outputs":[],"source":["# Group the data by 'Sentiment' and count occurrences\n","sentiment_counts = Merged_df['Sentiment'].value_counts().reset_index()\n","sentiment_counts.columns = ['Sentiment', 'Count']\n","\n","# Create a figure with two subplots\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n","\n","# Create a pie chart in the first subplot\n","wedges, texts, autotexts = ax1.pie(sentiment_counts['Count'], labels=sentiment_counts['Sentiment'], autopct='%1.1f%%',\n","         colors=sns.color_palette('Set3', len(sentiment_counts)))\n","ax1.set_title('Distribution of Sentiments')\n","\n","# Create a bar plot in the second subplot\n","sns.barplot(x='Sentiment', y='Count', data=sentiment_counts, ax=ax2, palette='Set3')\n","ax2.set_title('Sentiment Counts')\n","\n","# Add labels to the pie chart\n","for text, autotext in zip(texts, autotexts):\n","    text.set(size=12, weight=\"bold\")\n","    autotext.set(size=12, weight=\"bold\")\n","\n","# Adjust layout\n","plt.tight_layout()\n","\n","# Show the plots\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:12:05.046950Z","iopub.status.busy":"2024-07-23T09:12:05.046507Z","iopub.status.idle":"2024-07-23T09:12:05.166671Z","shell.execute_reply":"2024-07-23T09:12:05.165445Z","shell.execute_reply.started":"2024-07-23T09:12:05.046914Z"},"trusted":true},"outputs":[],"source":["import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# Assuming you have already calculated 'sentiment_counts' as described in your code\n","\n","# Create a pie chart\n","fig = px.pie(sentiment_counts, values='Count', names='Sentiment',\n","             title='Distribution of Sentiments',\n","             color_discrete_sequence=px.colors.qualitative.Set3)\n","\n","# Customize the pie chart\n","fig.update_traces(textinfo='percent+label')\n","fig.update_layout(showlegend=True)  # Show legend\n","\n","fig.update_layout(title_x=0.5)\n","\n","# Create a bar chart\n","bar_fig = px.bar(sentiment_counts, x='Sentiment', y='Count',\n","                  title='Sentiment Counts',\n","                  color='Sentiment', color_discrete_sequence=px.colors.qualitative.Set3)\n","\n","# Customize the bar chart\n","bar_fig.update_layout(showlegend=True)  # Show legend\n","\n","# Show both charts side by side\n","fig.show()\n","bar_fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-07-23T09:10:10.661154Z","iopub.status.idle":"2024-07-23T09:10:10.661534Z","shell.execute_reply":"2024-07-23T09:10:10.661375Z","shell.execute_reply.started":"2024-07-23T09:10:10.661356Z"},"trusted":true},"outputs":[],"source":["Merged_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T09:12:09.669281Z","iopub.status.busy":"2024-07-23T09:12:09.668898Z","iopub.status.idle":"2024-07-23T09:12:09.679854Z","shell.execute_reply":"2024-07-23T09:12:09.678633Z","shell.execute_reply.started":"2024-07-23T09:12:09.669253Z"},"trusted":true},"outputs":[],"source":["# Assuming you have the sentiment_counts DataFrame with columns 'Sentiment' and 'Count'\n","total_counts = sentiment_counts['Count'].sum()\n","\n","# Calculate the overall percentage for each sentiment category\n","positive_percentage = (sentiment_counts[sentiment_counts['Sentiment'] == 'positive']['Count'].sum() / total_counts) * 100\n","negative_percentage = (sentiment_counts[sentiment_counts['Sentiment'] == 'negative']['Count'].sum() / total_counts) * 100\n","neutral_percentage = (sentiment_counts[sentiment_counts['Sentiment'] == 'neutral']['Count'].sum() / total_counts) * 100\n","\n","# Print the overall percentages\n","print(f\"Overall Positive Percentage: {positive_percentage:.2f}%\")\n","print(f\"Overall Negative Percentage: {negative_percentage:.2f}%\")\n","print(f\"Overall Neutral Percentage: {neutral_percentage:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# User Engagement Summary:\n","\n","1. Almost each post has a good count of positive sentiment which suggests that people aren't being rude to the content they see.\n","2. If we look over the overall sentiment or user engagement in the posts, the positive sentiments come on top, with negative being the second and neutral playing a small part in it. But the good part is that majority of the people are engaging positivly with the posts that are on the platform"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2121672,"sourceId":3526532,"sourceType":"datasetVersion"}],"dockerImageVersionId":30553,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
